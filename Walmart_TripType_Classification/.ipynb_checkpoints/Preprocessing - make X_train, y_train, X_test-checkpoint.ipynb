{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "### part 1 : fill in missing values & clean\n",
    "\n",
    "- DepartmentDescription\n",
    "- FinelineNumber\n",
    "- Upc\n",
    "- All of DepartmentDescription, FinelineNumber, Upc is NaN\n",
    "- Divide the Upc into manufacturer(company) number and product number.\n",
    "    \n",
    "=======================================================================\n",
    "### part 2 : Encode & Derivation\n",
    "\n",
    "- DepartmentDescription\n",
    "- Weekday\n",
    "- FinelineNumber\n",
    "- company Upc\n",
    "- ScanCount\n",
    "    -  Divide by abs_scancount for each columns\n",
    "- Refund rate\n",
    "\n",
    "=======================================================================\n",
    "### part 3 : Feature Selection\n",
    "- Feature Selection\n",
    "\n",
    "- X_train\n",
    "- y_train\n",
    "- X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import preprocessing_functions as pf\n",
    "from functools import partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dca7ea3850d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(test.shape)\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1 : fill in missing values & clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DepartmentDescription\n",
    "- 각각의 VisitNumber 별 DepartmentDescription의 최빈값으로 DepartmentDescription의 빈값을 채운다.\n",
    "- 유추할 수 없는 191개의 값은 'UNKNOWN' 으로 대체한다.\n",
    "- \"MENSWEAR\" change to \"MENS WEAR\"\n",
    "- \"HEALTH AND BEAUTY AIDS\" change to \"BEAUTY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"DepartmentDescription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_VN_list = train[train[\"DepartmentDescription\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(DD_VN_list): # if: 특정 VisitNumber 따른 DepartmentDescription 값이 모두 비어있는 경우 제외\n",
    "    if len(train[train[\"VisitNumber\"] == loc][\"DepartmentDescription\"].value_counts().index) != 0:\n",
    "        train.loc[(train[\"VisitNumber\"] == loc)&(train[\"DepartmentDescription\"].isna()), \"DepartmentDescription\"] = train[train[\"VisitNumber\"] == loc][\"DepartmentDescription\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"DepartmentDescription\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"DepartmentDescription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_VN_list_t = test[test[\"DepartmentDescription\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(DD_VN_list_t): # if: 특정 VisitNumber 따른 DepartmentDescription 값이 모두 비어있는 경우 제외\n",
    "    if len(test[test[\"VisitNumber\"] == loc][\"DepartmentDescription\"].value_counts().index) != 0:\n",
    "        test.loc[(test[\"VisitNumber\"] == loc)&(test[\"DepartmentDescription\"].isna()), \"DepartmentDescription\"] = test[test[\"VisitNumber\"] == loc][\"DepartmentDescription\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"DepartmentDescription\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### refine DepartmentDescription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"MENSWEAR\" change to \"MENS WEAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"DepartmentDescription\"] == \"MENSWEAR\", \"DepartmentDescription\"] = \"MENS WEAR\"\n",
    "train[train[\"DepartmentDescription\"] == \"MENSWEAR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"HEALTH AND BEAUTY AIDS\" change to \"BEAUTY\"\n",
    "- train data has only two rows of \"HEALTH AND BEAUTY AIDS\", and test data doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"DepartmentDescription\"] == \"HEALTH AND BEAUTY AIDS\", \"DepartmentDescription\"] = \"BEAUTY\"\n",
    "train[train[\"DepartmentDescription\"] == \"HEALTH AND BEAUTY AIDS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinelineNumber\n",
    "- DepartmentDescription이 'PHARMACY RX'일때, FinelineNumber가 빈값인 경우 DepartmentDescription이 'PHARMACY RX'일때의 FinelineNumber의 최빈값으로 채운다.\n",
    "- 각각의 VisitNumber 별 FinelineNumber의 최빈값으로 FinelineNumber의 빈값을 채운다.\n",
    "- 191개의 유추할 수 없는 값은 기존에 있던 값과 중복되지 않는 -9999 값으로 대체한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[train[\"DepartmentDescription\"] == 'PHARMACY RX'][\"FinelineNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pharmacy_idx = train[train[\"DepartmentDescription\"]=='PHARMACY RX'].index\n",
    "number_idx = np.arange(2922)\n",
    "idx_box = zip(number_idx, Pharmacy_idx)\n",
    "\n",
    "\n",
    "for idx, Pha_idx in tqdm(idx_box):\n",
    "    if idx % 2 == 0:\n",
    "        train.loc[Pha_idx, \"FinelineNumber\"] = 4822.0\n",
    "    else:\n",
    "        train.loc[Pha_idx, \"FinelineNumber\"] = 5615.0\n",
    "        \n",
    "train[train[\"DepartmentDescription\"] == 'PHARMACY RX'][[\"DepartmentDescription\", \"FinelineNumber\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"FinelineNumber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_VN_list = train[train[\"FinelineNumber\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(FN_VN_list): # if: 특정 VisitNumber 따른 FinelineNumber 값이 모두 비어있는 경우 제외\n",
    "    if len(train[train[\"VisitNumber\"] == loc][\"FinelineNumber\"].value_counts().index) != 0:\n",
    "        train.loc[(train[\"VisitNumber\"] == loc)&(train[\"FinelineNumber\"].isna()), \"FinelineNumber\"] = train[train[\"VisitNumber\"] == loc][\"FinelineNumber\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"FinelineNumber\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test[\"DepartmentDescription\"] == 'PHARMACY RX'][\"FinelineNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pharmacy_idx = test[test[\"DepartmentDescription\"]=='PHARMACY RX'].index\n",
    "number_idx = np.arange(2784)\n",
    "idx_box = zip(number_idx, Pharmacy_idx)\n",
    "\n",
    "\n",
    "for idx, Pha_idx in tqdm(idx_box):\n",
    "    if idx % 2 == 0:\n",
    "        test.loc[Pha_idx, \"FinelineNumber\"] = 4822.0\n",
    "    else:\n",
    "        test.loc[Pha_idx, \"FinelineNumber\"] = 5615.0\n",
    "        \n",
    "test[test[\"DepartmentDescription\"] == 'PHARMACY RX'][[\"DepartmentDescription\", \"FinelineNumber\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"FinelineNumber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_VN_list_t = test[test[\"FinelineNumber\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(FN_VN_list_t): # if: 특정 VisitNumber 따른 FinelineNumber 값이 모두 비어있는 경우 제외\n",
    "    if len(test[test[\"VisitNumber\"] == loc][\"FinelineNumber\"].value_counts().index) != 0:\n",
    "        test.loc[(test[\"VisitNumber\"] == loc)&(test[\"FinelineNumber\"].isna()), \"FinelineNumber\"] = test[test[\"VisitNumber\"] == loc][\"FinelineNumber\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"FinelineNumber\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPC\n",
    "- DepartmentDescription이 'PHARMACY RX'일때, UPC가 빈값인 경우 DepartmentDescription이 'PHARMACY RX'일때의 UPC의 최빈값으로 채운다.\n",
    "- 각각의 VisitNumber 별 UPC의 최빈값으로 UPC의 빈값을 채운다.\n",
    "- 191개의 유추할 수 없는 값은 기존에 있던 값과 중복되지 않는 '0000599996' 값으로 대체한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"Upc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upc_VN_list = train[train[\"Upc\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(Upc_VN_list): # if: 특정 VisitNumber 따른 Upc 값이 모두 비어있는 경우 제외\n",
    "    if len(train[train[\"VisitNumber\"] == loc][\"Upc\"].value_counts().index) != 0:\n",
    "        train.loc[(train[\"VisitNumber\"] == loc)&(train[\"Upc\"].isna()), \"Upc\"] = train[train[\"VisitNumber\"] == loc][\"Upc\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"VisitNumber\"]==259, \"Upc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"Upc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upc_VN_list_t = test[test[\"Upc\"].isna()][\"VisitNumber\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm(Upc_VN_list_t): # if: 특정 VisitNumber 따른 Upc 값이 모두 비어있는 경우 제외\n",
    "    if len(test[test[\"VisitNumber\"] == loc][\"Upc\"].value_counts().index) != 0:\n",
    "        test.loc[(test[\"VisitNumber\"] == loc)&(test[\"Upc\"].isna()), \"Upc\"] = test[test[\"VisitNumber\"] == loc][\"Upc\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"VisitNumber\"]==874, \"Upc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  All of DepartmentDescription, FinelineNumber, Upc is NaN\n",
    "\n",
    "- 총 191개의 다른 컬럼과의 관계로 추론 불가능한 DepartmentDescription, FinelineNumber, Upc의 값이 모두 비어있는 경우, 기존에 train, test 데이터에 없는 \"UNKNOWN\", -9999, '0000599996' 값으로 각각 채운다.\n",
    "- 이 경우에 모든 row들은 TripType이 999이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = train[(train[\"DepartmentDescription\"].isna())&(train[\"DepartmentDescription\"].isna())&(train[\"DepartmentDescription\"].isna())][[\"VisitNumber\", \"DepartmentDescription\", \"FinelineNumber\", \"Upc\", \"TripType\", \"Weekday\", \"ScanCount\"]]\n",
    "\n",
    "print(empty_df.shape)\n",
    "empty_df[[\"DepartmentDescription\", \"FinelineNumber\", \"Upc\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"191개의 빈 row들은 모두 triptype이 {}이다.\".format(empty_df[\"TripType\"].value_counts().index[0]))\n",
    "empty_df[\"TripType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"DepartmentDescription\"].isna(), \"DepartmentDescription\"] = \"UNKNOWN\"\n",
    "train[train[\"DepartmentDescription\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"FinelineNumber\"].isna(), \"FinelineNumber\"] = -9999.0\n",
    "train[train[\"FinelineNumber\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"Upc\"].isna(), \"Upc\"] = 0000599996.0\n",
    "train[train[\"Upc\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"DepartmentDescription\"].isna(), \"DepartmentDescription\"] = \"UNKNOWN\"\n",
    "test[test[\"DepartmentDescription\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"FinelineNumber\"].isna(), \"FinelineNumber\"] = -9999.0\n",
    "test[test[\"FinelineNumber\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"Upc\"].isna(), \"Upc\"] = 0000599996.0\n",
    "test[test[\"Upc\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the Upc into manufacturer(company) number and product number.\n",
    "\n",
    "- 3~12자리의 여러자기 종류의 UPC를 모두 12자리로 복원 후, 분류에 필요하다고 판단한 company_Upc와 product_Upc로 나누어 인코딩\n",
    "- preprocessing function 사용(custom function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Upc\"] = train[\"Upc\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"full_Upc\"] = train[\"Upc\"].apply(pf.upc_789101112_to_10)\n",
    "train[\"full_Upc\"] = train[\"full_Upc\"].apply(pf.upc_3456_to_10)\n",
    "\n",
    "train[\"company_Upc\"] = train[\"full_Upc\"].apply(pf.company_part_Upc)\n",
    "train[\"product_Upc\"] = train[\"full_Upc\"].apply(pf.product_part_Upc) \n",
    "\n",
    "train[[\"Upc\", \"full_Upc\", \"company_Upc\", \"product_Upc\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Upc\"] = test[\"Upc\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"full_Upc\"] = test[\"Upc\"].apply(pf.upc_789101112_to_10)\n",
    "test[\"full_Upc\"] = test[\"full_Upc\"].apply(pf.upc_3456_to_10)\n",
    "\n",
    "test[\"company_Upc\"] = test[\"full_Upc\"].apply(pf.company_part_Upc)\n",
    "test[\"product_Upc\"] = test[\"full_Upc\"].apply(pf.product_part_Upc) \n",
    "\n",
    "test[[\"Upc\", \"full_Upc\", \"company_Upc\", \"product_Upc\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2 : Encode & Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the DepartmentDescription for each VisitNumber(Encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_department = pd.pivot_table(data=train, index='VisitNumber', columns='DepartmentDescription', values='ScanCount', aggfunc='sum')\n",
    "train_department = train_department.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_department = pd.pivot_table(data=test, index='VisitNumber', columns='DepartmentDescription', values='ScanCount', aggfunc='sum')\n",
    "test_department = test_department.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_department.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the Weekday for each VisitNumber(Encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weekday = pd.pivot_table(data=train, index='VisitNumber', columns='Weekday', values='ScanCount', aggfunc='sum')\n",
    "train_weekday = train_weekday.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weekday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weekday = pd.pivot_table(data=test, index='VisitNumber', columns='Weekday', values='ScanCount', aggfunc='sum')\n",
    "test_weekday = test_weekday.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weekday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the FinelineNumber for each VisitNumber(Encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fineline = pd.pivot_table(data=train, index='VisitNumber', columns='FinelineNumber', values='ScanCount', aggfunc='sum')\n",
    "train_fineline = train_fineline.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_fineline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fineline = pd.pivot_table(data=test, index='VisitNumber', columns='FinelineNumber', values='ScanCount', aggfunc='sum')\n",
    "test_fineline = test_fineline.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fineline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the company_Upc for each VisitNumber(Encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"company_Upc\"] = train[\"company_Upc\"].astype('str')\n",
    "train_company_upc = pd.pivot_table(data=train, index='VisitNumber', columns='company_Upc', values='ScanCount', aggfunc='sum')\n",
    "train_company_upc = train_company_upc.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_company_upc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"company_Upc\"] = test[\"company_Upc\"].astype('str')\n",
    "test_company_upc = pd.pivot_table(data=test, index='VisitNumber', columns='company_Upc', values='ScanCount', aggfunc='sum')\n",
    "test_company_upc = test_company_upc.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_company_upc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat above columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_department, train_fineline, train_company_upc, train_weekday], axis=1)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_department, test_fineline, test_company_upc, test_weekday], axis=1)\n",
    "test_df = test_df.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파생 컬럼 생성을 위한 abs_ScanCount생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"abs_ScanCount\"] = np.abs(train[\"ScanCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abs_ScanCount = train.groupby(by=\"VisitNumber\").sum().reset_index()[\"abs_ScanCount\"]\n",
    "train_abs_ScanCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ScanCount = train.groupby(by=\"VisitNumber\").sum().reset_index()[\"ScanCount\"]\n",
    "train_ScanCount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"abs_ScanCount\"] = np.abs(test[\"ScanCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abs_ScanCount = test.groupby(by=\"VisitNumber\").sum().reset_index()[\"abs_ScanCount\"]\n",
    "test_abs_ScanCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ScanCount = test.groupby(by=\"VisitNumber\").sum().reset_index()[\"ScanCount\"]\n",
    "test_ScanCount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide by abs_scancount for each columns\n",
    "- ScanCount로 각 컬럼을 나눠 산 물건 종류의 비율을 할당\n",
    "- 절대값 사용 이유는 한번 샀다가 환불한 경우도 구매했던 이력으로 간주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=False)\n",
    "train_df[\"abs_ScanCount\"] = train_abs_ScanCount\n",
    "\n",
    "train_columns = list(train_df.columns)\n",
    "\n",
    "for col_name in tqdm(train_columns):\n",
    "    train_df[col_name] = train_df[col_name] / train_df[\"abs_ScanCount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=False)\n",
    "test_df[\"abs_ScanCount\"] = test_abs_ScanCount\n",
    "test_columns = list(test_df.columns)\n",
    "\n",
    "for col_name in tqdm(test_columns):\n",
    "    test_df[col_name] = test_df[col_name] / test_df[\"abs_ScanCount\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refund rate\n",
    "- 999타입은 대부분이 환불 고객이며, 환불 비율에 따라 고객 유형 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"ScanCount\"] = train_ScanCount\n",
    "train_df[\"refund_rate\"] = ((train_abs_ScanCount - train_ScanCount) / 2) / train_abs_ScanCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"refund_rate\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"ScanCount\"] = test_ScanCount\n",
    "test_df[\"refund_rate\"] = ((test_abs_ScanCount - test_ScanCount) / 2) / test_abs_ScanCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"refund_rate\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part3 : Feature Selection\n",
    "- feature로 필요하지 않은 abs_ScanCount, VisitNumber 제거\n",
    "- train, test 데이터 중 중복되는 company_upc(5304 columns), finelinenumber(5045 columns)만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df[\"abs_ScanCount\"]\n",
    "del train_df[\"VisitNumber\"]\n",
    "\n",
    "del test_df[\"abs_ScanCount\"]\n",
    "del test_df[\"VisitNumber\"]\n",
    "\n",
    "train_company_list = list(train[\"company_Upc\"].value_counts().index)\n",
    "test_company_list = list(test[\"company_Upc\"].value_counts().index)\n",
    "\n",
    "train_fineline_list = list(train[\"FinelineNumber\"].value_counts().index)\n",
    "test_fineline_list = list(test[\"FinelineNumber\"].value_counts().index)\n",
    "\n",
    "company_feature = list(set(train_company_list) & set(test_company_list))\n",
    "fineline_feature = list(set(train_fineline_list) & set(test_fineline_list))\n",
    "\n",
    "feature_names = list(train_department.columns) + list(train_weekday.columns) + company_feature + fineline_feature + [\"ScanCount\", \"refund_rate\"]\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df[feature_names]\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.groupby(by=\"VisitNumber\").mean().reset_index()[\"TripType\"]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = test_df[feature_names]\n",
    "\n",
    "print(X_test.shape)\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse matrix - csr matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = csr_matrix(X_train)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = csr_matrix(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
